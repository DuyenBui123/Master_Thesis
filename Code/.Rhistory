x
x<- 5
x
library(Rcdmr)
utils:::menuInstallPkgs()
library(Rcdmr)
library(Rcmdr)
q()
q()
q()
############################################################################
#### script AEO_LiDAR_AHN3
#### V1.0 2018-03-06
#### Harm Bartholomeus
####
#### AEO exercise on AHN3 lidar processing
####
#### Instructions: Go through the script step by step and execute the R-code
#### (select code and Ctrl-R). Answer the questions in a seperate document.
#### If required you can also copy the figures to this answer document.
############################################################################
# For this part of the exercise you will work with pointcloud data which are collected for the
# creation of the Actueel Hoogtemodel Nederland (up-to-date elevation model of the Netherlands),
# version 3 (AHN3). Those data are collected every 6-7 years by means of Airborne Laser Scanning
# to create a Digital Terrain Model with a spatial resolution of 5m. Next to the rasterized DTM
# the pointcloud data are provided.
# #
# # The pointclouds are delivered in .las/.laz format where all individual points have been
# classified into the classes: ground, building, water, artificial object or other
# (ref: https://www.pdok.nl/nl/ahn3-downloads). Next to that, some additional attributes are
# recorded for each point. The .las format is a binary format which is used to store and exchange
# LiDAR data. A .laz file is a zipped/compressed version, which reduces the file size to ~10%
# without loss of information.
# #
# # Since a few years the data are openly available through https://www.pdok.nl/nl/producten/pdok-downloads/atomfeeds
# (AHN1 and AHN2) and https://www.pdok.nl/nl/ahn3-downloads (AHN3) . AHN1 and AHN2 data cover the whole of
# the Netherlands, AHN3 has now been released for part of the Netherlands (status early 2018)
# #
# # For the exercise the Tile: 39EZ2, covering the area around Rhenen was downloaded, which has
# a file size of 2.5 GB in .laz format. Since this is a bit too much to process on the computers
# used during the course tiles of 200*200 m were created using the LAStile function in Lastools
# (https://rapidlasso.com/lastools/). This software is also available for use during the practicals!
# See download section on blackboard, including the software license. Much of the functionality we show
# in the rest of the practical can be done in LAStools as well, where LAStools is better capable to deal
# with very large datasets.
#
# For information on the functions check the lidR documentation on https://cran.r-project.org/web/packages/lidR/lidR.pdf
#
# And... when scripting... Google is your friend!
#### INSTALL PACKAGES ####
# in the PC rooms this can't be done with the script, so please do it manually:
# Go to: Tools - Install Packages
# As a repositry select: CRAN/CRANextra
# As a library path select: "C:/Program Files/R/R-3.4.3/library"
# you can install multiple packages at once, so just copy the names given below:
# raster, lidR, colorRamps, sp, rgl
### pressing Install will start the installation which may take about 5 mins (coffee!)
install.packages("lidR", "raster", "colorRamps", "sp", "rgl") ## normally running this works as well, but not in the pc rooms
# Load the dataset
data("Nile")
# Display the first few entries of the dataset
# Plot the time series
plot(Nile, main = "Annual Flow of the Nile River"
, ylab = "Flow (cubic meters per second)", xlab = "Year")
# Summary of the Nile dataset
summary(Nile)
install.packages("Rbeast")
library(Rbeast)
out = beast(Nile, season='none') #  'none': trend-only data without seasonlaity
print(out)
plot(out)
install.packages(c("strucchangeRcpp", "bfast"))
library(remotes)
install_github("bfast2/strucchangeRcpp")
install_github("bfast2/bfast")
library(bfastLite)
install.packages(c("strucchangeRcpp", "bfast"))
library(remotes)
install_github("bfast2/strucchangeRcpp")
install_github("bfast2/bfast")
library(bfastLite)
install.packages(c("strucchangeRcpp", "bfast"))
datats <- ts(rowSums(simts$time.series))
plot(simts) # stl object containing simulated NDVI time series
# Load the dataset
data("Nile")
# Display the first few entries of the dataset
# Plot the time series
plot(Nile, main = "Annual Flow of the Nile River"
, ylab = "Flow (cubic meters per second)", xlab = "Year")
# Summary of the Nile dataset
summary(Nile)
install.packages("Rbeast")
library(Rbeast)
out = beast(Nile, season='none') #  'none': trend-only data without seasonlaity
print(out)
plot(out)
getwd()
getwd()
setwd("C:/Master_Thesis/Code")
# load packages
if (!require("pacman")) install.packages("pacman"); library(pacman)
# load packages
install.packages("pacman"); library(pacman)
install.packages("pacman")
if (!require("pacman")) install.packages("pacman"); library(pacman)
library(pacman)
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load(here, devtools, sf, data.table, tidyverse, pbapply, parallel)
source(here("Code", "Utils", "gradual_validation.R"))
source(here("Utils", "gradual_validation.R"))
getwd()
source(here("Utils", "gradual_validation.R"))
# source external functions
here::i_am("Code\\Utils\\gradual_validation.R")
source(here("Code","Utils", "gradual_validation.R"))
# # add progress bar option to show it in the terminal
pbo <- pboptions(type="timer")
mycores <- detectCores()
NDVI_output <-read.csv("C:\\Master_Thesis\\Intermediate product\\cloud_free_product\\_L8_NDVI_output_BFASTLite.csv")
cal_comb_ref <-read.csv("C:\\Master_Thesis\\Intermediate product\\cal_compl_data.csv")
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
cal_comb_ref
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
cal_comb_ref$reference_year
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
algo_df$sample_id
NDVI_output$sample_id
NDVI_output
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
cal_compl_data <-read.csv(C:/Master_Thesis/Intermediate product/cal_compl_data.csv)
cal_compl_data <-read.csv("C:/Master_Thesis/Intermediate product/cal_compl_data.csv")
for(i in 1:length(cal_compl_data) (if (cal_compl_data$change_at_100m[i] == FALSE) {cal_compl_data$change_yr[i] <- ""} esle {cal_compl_data$change_yr[i] <- cal_compl_data$reference_year[i]}))
for(i in 1:length(cal_compl_data)) {if (cal_compl_data$change_at_100m[i] == FALSE) {cal_compl_data$change_yr[i] <- ""}
esle {cal_compl_data$change_yr[i] <- cal_compl_data$reference_year[i]}}
for(i in 1:length(cal_compl_data)) {if (cal_compl_data$change_at_100m[i] == "FALSE") {cal_compl_data$change_yr[i] <- ""}
esle {cal_compl_data$change_yr[i] <- cal_compl_data$reference_year[i]}}
else {cal_compl_data$change_yr[i] <- cal_compl_data$reference_year[i]}}
for (i in 1:length(cal_compl_data$change_at_100m)) {
if (cal_compl_data$change_at_100m[i] == "FALSE") {
cal_compl_data$change_yr[i] <- ""
} else {
cal_compl_data$change_yr[i] <- cal_compl_data$reference_year[i]
}
}
for (i in 1:length(cal_compl_data$change_at_100m)) {
if (cal_compl_data$change_at_100m[i] == "FALSE") {
cal_compl_data$change_yr[i] <- ""
} else {
cal_compl_data$change_yr[i] <- cal_compl_data$reference_year[i]
}
}
cal_compl_data <-read.csv("C:/Master_Thesis/Intermediate product/cal_compl_data.csv")
for (i in 1:length(cal_compl_data$change_at_100m)) {
if (cal_compl_data$change_at_100m[i] == "FALSE") {
cal_compl_data$change_yr[i] <- ""
} else {
cal_compl_data$change_yr[i] <- cal_compl_data$reference_year[i]
}
}
cal_compl_data
cal_compl_data[cal_compl_data$change_yr != "",]
# Convert integer to numeric with three decimal for change_yr column
cal_compl_data$change_yr <- noquote(format(cal_compl_data$change_yr, digits=3, nsmall=3))
# Write a csv file for calibration data
file_path_cal <- "C:/Master_Thesis/Intermediate product/cal_compl_data.csv"
write.csv(cal_compl_data, file_path_cal)
val_compl_data <- read.csv('C:\\Master_Thesis\\Intermediate product\\val_compl_data.csv')
for (i in 1:length(val_compl_data$change_at_100m)) {
if (val_compl_data$change_at_100m[i] == "FALSE") {
val_compl_data$change_yr[i] <- ""
} else {
val_compl_data$change_yr[i] <- val_compl_data$reference_year[i]
}
}
# Convert integer to numeric with three decimal for change_yr column
val_compl_data$change_yr <- noquote(format(val_compl_data$change_yr, digits=3, nsmall=3))
val_compl_data$change_yr
# Write a csv file for validation data
write.csv(val_compl_data,'C:\\Master_Thesis\\Intermediate product\\val_compl_data.csv')
cal_comb_ref <-read.csv("C:\\Master_Thesis\\Intermediate product\\cal_compl_data.csv")
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
source(here("Code","Utils", "gradual_validation.R"))
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
cal_comb_ref[cal_comb_ref$sample_id==1020561,]
cal_comb_ref[cal_comb_ref$sample_id==1020561,]$change_yr
length(cal_comb_ref[cal_comb_ref$sample_id==1020561,]$change_yr)
x <- cal_comb_ref[cal_comb_ref$sample_id==1020561,]
TruthDates <- x[x$change_at_100m == TRUE,]$change_yr
TruthDates
x <- cal_comb_ref[cal_comb_ref$sample_id==1022254,]
TruthDates <- x[x$change_at_100m == TRUE,]$change_yr
TruthDates
x <- cal_comb_ref[cal_comb_ref$sample_id==1020561,]
x$change_at_100m == TRUE
x[x$change_at_100m == TRUE,]
TruthDates <- x[x$change_at_100m == TRUE,]$change_yr
TruthDates
length(TruthDates)
BreakTimes <- NDVI_output[NDVI_output$sample_id == 1020561,]$Breakpoint
BreakTimes
length(BreakTimes) > 0
if (length(BreakTimes) > 0)
if (length(BreakTimes) > 0){
BreakTimes = BreakTimes[BreakTimes > 2016 - 1 & BreakTimes < 2019 + 1]}
BreakTimes = BreakTimes[BreakTimes > 2016 - 1 & BreakTimes < 2019 + 1]
BreakTimes
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
source(here("Code","Utils", "gradual_validation.R"))
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
NDVI_conf <- validateAlgorithmTotal(ref_df = cal_comb_ref,
algo_df = NDVI_output,
fpstats = FALSE,
cl= mycores)
# load packages
install.packages("pacman");
install.packages("pacman")
library(pacman)
# load packages
install.packages("pacman");
library(pacman)
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load(here, devtools, sf, data.table, tidyverse, pbapply, parallel)
# source external functions
here::i_am("Code\\Utils\\gradual_validation.R")
source(here("Code","Utils", "gradual_validation.R"))
# # add progress bar option to show it in the terminal
pbo <- pboptions(type="timer")
mycores <- detectCores()
NDVI_output <-read.csv("C:\\Master_Thesis\\Intermediate product\\cloud_free_product\\_L8_NDVI_output_BFASTLite.csv")
cal_comb_ref <-read.csv("C:\\Master_Thesis\\Intermediate product\\cal_compl_data.csv")
